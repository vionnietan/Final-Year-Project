{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook for Cancer Predictive Model\n",
    "## By: Group CL_04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import os, random, shutil\n",
    "import copy\n",
    "\n",
    "# Torch Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.io import read_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing Dataset (60% training, 20% validation, 20% testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://stackoverflow.com/questions/53074712/how-to-split-folder-of-images-into-test-training-validation-sets-with-stratified\n",
    "def img_train_val_test_split(root_dir):\n",
    "    \"\"\"\n",
    "    This function splits a folder with subfolders into train, test and validation datasets\n",
    "    :param root_dir: a string corresponding to the file path of the folder of subfolders of images,\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # A list of strings of subfolder names\n",
    "    classes_dir = ['MSIMUT_JPEG', 'MSS_JPEG']\n",
    "\n",
    "    # Ratio of validation and test datasets\n",
    "    val_ratio = 0.20\n",
    "    test_ratio = 0.20\n",
    "\n",
    "    for cls in classes_dir:\n",
    "        # Create Train / Val / Test directory for cls\n",
    "        os.makedirs(root_dir + 'train/' + cls)\n",
    "        os.makedirs(root_dir + 'val/' + cls)\n",
    "        os.makedirs(root_dir + 'test/' + cls)\n",
    "\n",
    "        # Get pathname of cls\n",
    "        src = root_dir + cls  # Folder to copy images from\n",
    "\n",
    "        # split the filenames into chosen training and testing ratio\n",
    "        allFileNames = os.listdir(src)\n",
    "        np.random.shuffle(allFileNames)\n",
    "        train_FileNames, val_FileNames, test_FileNames = np.split(np.array(allFileNames),\n",
    "                                                                  [int(len(allFileNames) * (1 - (val_ratio + test_ratio))),\n",
    "                                                                   int(len(allFileNames) * (1 - val_ratio)),\n",
    "                                                                   ])\n",
    "       \n",
    "        # copy images into new train folder for cls subfolder\n",
    "        for name in train_FileNames:\n",
    "            shutil.copy(root_dir + cls + '/' + name, root_dir + 'train/' + cls)\n",
    "\n",
    "        # copy images into new validation folder for cls subfolder\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(root_dir + cls + '/' + name, root_dir + 'val/' + cls)\n",
    "\n",
    "        # copy images into new test folder for cls subfolder\n",
    "        for name in test_FileNames:\n",
    "            shutil.copy(root_dir + cls + '/' + name, root_dir + 'test/' + cls)\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root_dir: filepath of coad_msi_mss (cancer datasets) with '/' at the back\n",
    "root_dir = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train_val_test_split(root_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Data Augmentation and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Preprocessing of Images for Training and Validation datasets.\n",
    "\n",
    "data_transformation_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # ImageNet standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # ImageNet standards\n",
    "    ])\n",
    "\n",
    "data_transformation_val = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory of training dataset\n",
    "root_dir_train = ''\n",
    "\n",
    "# Set directory of validation dataset\n",
    "root_dir_val = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Apply preprocessing to training and validation datasets using root directory and transformations specified\n",
    "train_image_dataset = datasets.ImageFolder(root = root_dir_train, transform=data_transformation_train)\n",
    "val_image_dataset = datasets.ImageFolder(root = root_dir_val, transform=data_transformation_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DataLoader for training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "trainloader = DataLoader(train_image_dataset, batch_size=16, shuffle=True)\n",
    "valloader = DataLoader(val_image_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization (Display some images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/kvarun07/covid-19-detection/blob/main/Covid-19-detection.ipynb\n",
    "# Get class names (MSIMUT, MSS)\n",
    "class_names = trainloader.dataset.classes\n",
    "\n",
    "def show_images(images, labels, preds):\n",
    "    \"\"\"\n",
    "    This function displays the images to provide a visualization of the data augmentations done on the training\n",
    "    dataset.\n",
    "    :param images: The current DataLoader of the image at which data augmentation has been done\n",
    "    :param labels: The current label of the image\n",
    "    :param preds: The predicted label of the image in training dataset\n",
    "    :return: a subplot of 1 by 6 cancer images with their labels and predicted labels\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,4))\n",
    "    for i, image in enumerate(images):\n",
    "        if i < 5:\n",
    "            plt.subplot(1, 6, i+1, xticks=[], yticks=[])\n",
    "            \n",
    "            # Convert to from tensor to numpy by taking its transpose\n",
    "            image = image.numpy().transpose((1, 2, 0))  # Set axes\n",
    "            \n",
    "            # Denormalise image to show, as images were normalised earlier\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            \n",
    "            image = image*std + mean\n",
    "            image = np.clip(image, 0.,1.)\n",
    "            plt.imshow(image)\n",
    "            \n",
    "            colour = 'green' if preds[i] == labels[i] else 'red'\n",
    "            \n",
    "            plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
    "            plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=colour)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://github.com/kvarun07/covid-19-detection/blob/main/Covid-19-detection.ipynb\n",
    "# Retrieve batch of training data\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "# Since predictions are not available for training data yet\n",
    "# Labels are used in place of predictions\n",
    "show_images(images, labels, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model - Load resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Load resnet50 pre-trained model\n",
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model - Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Backprop to every parameter, finetuning the convnet instead of feature extraction\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# Classifier architecture to put on top of resnet50\n",
    "fc_inputs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Sequential(\n",
    "    nn.Linear(fc_inputs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 10),\n",
    "    nn.LogSoftmax(dim=1)\n",
    ")\n",
    "\n",
    "# Set criterion of model (loss function)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Set Optimizer parameters - make sure all parameters are being optimized\n",
    "optimizer = optim.Adam(resnet50.parameters(),lr=0.0001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "# Send resnet50 model to GPU\n",
    "resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Note training losses and acc, alongside validation losses and acc for visualization after training\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "\n",
    "val_losses = []\n",
    "val_acc = []\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs):\n",
    "    \"\"\"\n",
    "    This function trains the current model, each epoch has a training and validation phase\n",
    "    :param model: The current resnet50 model loaded \n",
    "    :param criterion: Criterion set to the model\n",
    "    :param optimizer: The optimizer parameter of the model\n",
    "    :param scheduler: LR Scheduler Object\n",
    "    :param num_epochs: Number of epochs the train_model function is going to run for\n",
    "    :return: Each epoch with a training and validation loss, alongside their accuracy and saves the best\n",
    "    model with highest accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Take note of time\n",
    "    since = time.time()\n",
    "    \n",
    "    # Deep copy the best model\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Run for num_epochs times\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('--' * 5)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                condition = trainloader\n",
    "                size = len(train_image_dataset)\n",
    "            else:\n",
    "                condition = valloader\n",
    "                size = len(val_image_dataset)\n",
    "\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in condition:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "            epoch_loss = running_loss / size\n",
    "            epoch_acc = running_corrects.double() / size\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val':\n",
    "                val_losses.append(epoch_loss)\n",
    "                val_acc.append(epoch_acc)\n",
    "            else:\n",
    "                train_losses.append(epoch_loss)\n",
    "                train_acc.append(epoch_acc)\n",
    "                \n",
    "            # deep copy the model\n",
    "            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Set number of epochs to train\n",
    "num_epochs = 35\n",
    "\n",
    "# Call train_model function with the model, criterion, optimizer, scheduler and number of epochs as parameters\n",
    "best_model = train_model(resnet50, criterion, optimizer, exp_lr_scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses of training and validation \n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lst = []\n",
    "for i in range(len(train_acc)):\n",
    "    train_lst.append(float(train_acc[i]))\n",
    "\n",
    "val_lst = []\n",
    "for i in range(len(val_acc)):\n",
    "    val_lst.append(float(val_acc[i]))\n",
    "\n",
    "plt.plot(train_lst, label='Training Acc')\n",
    "plt.plot(val_lst, label='Validation Acc')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "# Save the best model\n",
    "PATH = ''\n",
    "torch.save(best_model.state_dict(), PATH)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "39a190c749d32fb61bac8622a44c3427ad612ce63b074d3a9247eb6341a0f9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
