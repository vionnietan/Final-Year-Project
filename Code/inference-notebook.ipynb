{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import Libraries\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import torch\n",
                "import pandas as pd\n",
                "\n",
                "from torch import nn\n",
                "from torch import optim\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision import datasets, transforms, models\n",
                "from PIL import Image\n",
                "from torch.autograd import Variable\n",
                "from typing import Union\n",
                "from PIL import Image\n",
                "from torch import Tensor"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SOURCE: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
                "\n",
                "# Set directory of testing folder\n",
                "root_dir_test = ''\n",
                "\n",
                "# Prelimnary data transformations done on testing dataset\n",
                "data_transformation_test = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
                "\n",
                "# Apply preprocessing and load dataloader with described batch size\n",
                "test_image_dataset = datasets.ImageFolder(root = root_dir_test, transform=data_transformation_test)\n",
                "testloader = DataLoader(test_image_dataset, batch_size=16, shuffle=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set model to be sent to cpu\n",
                "device = torch.device(\"cpu\")\n",
                "\n",
                "# Load the resnet50 model\n",
                "model = models.resnet50()\n",
                "\n",
                "# Determine the classifier architecture for the model\n",
                "num_inftr = model.fc.in_features\n",
                "model.fc = nn.Sequential(\n",
                "    nn.Linear(num_inftr, 256),\n",
                "    nn.ReLU(),\n",
                "    nn.Dropout(0.4),\n",
                "    nn.Linear(256, 10),\n",
                "    nn.LogSoftmax(dim=1)\n",
                ")\n",
                "\n",
                "# Load the model in directory, set to cpu and evaluation mode\n",
                "model.load_state_dict(torch.load('model.pth',map_location=torch.device('cpu')))\n",
                "model.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SOURCE: https://github.com/kvarun07/covid-19-detection/blob/main/Covid-19-detection.ipynb\n",
                "# Get class names (MSIMUT, MSS)\n",
                "class_names = testloader.dataset.classes\n",
                "\n",
                "def show_images(images, labels, preds):\n",
                "    \"\"\"\n",
                "    This function displays the images to provide a visualization of the data augmentations done on the training\n",
                "    dataset.\n",
                "    :param images: The current DataLoader of the image at which data augmentation has been done\n",
                "    :param labels: The current label of the image\n",
                "    :param preds: The predicted label of the image in training dataset\n",
                "    :return: a subplot of 1 by 6 cancer images with their labels and predicted labels\n",
                "    \"\"\"\n",
                "    plt.figure(figsize=(8,4))\n",
                "    for i, image in enumerate(images):\n",
                "        if i < 5:\n",
                "            plt.subplot(1, 6, i+1, xticks=[], yticks=[])\n",
                "\n",
                "            # Convert to from tensor to numpy by taking its transpose\n",
                "            image = image.numpy().transpose((1, 2, 0))\n",
                "            \n",
                "            # Denormalise image to show, as images were normalised earlier\n",
                "            mean = np.array([0.485, 0.456, 0.406])\n",
                "            std = np.array([0.229, 0.224, 0.225])\n",
                "            \n",
                "            image = image*std + mean\n",
                "            image = np.clip(image, 0.,1.)\n",
                "            plt.imshow(image)\n",
                "            \n",
                "            colour = 'green' if preds[i] == labels[i] else 'red'\n",
                "            plt.xlabel(f'{class_names[int(labels[i].numpy())]}')\n",
                "            plt.ylabel(f'{class_names[int(preds[i].numpy())]}', color=colour)\n",
                "    plt.tight_layout()        \n",
                "    plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SOURCE: https://github.com/kvarun07/covid-19-detection/blob/main/Covid-19-detection.ipynb\n",
                "def show_preds():\n",
                "    \"\"\"\n",
                "    This function sets the model to evaluation mode to retrieve batches of testing data and predict its\n",
                "    class labels using the model loaded earlier\n",
                "    \"\"\"\n",
                "    model.eval()    # set to evaluation mode\n",
                "    images, labels = next(iter(testloader))\n",
                "    outputs = model(images)\n",
                "    _ , preds = torch.max(outputs, 1)\n",
                "    show_images(images, labels, preds)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Call show_preds() function to plot a 1 by 5 subplot of images alongside its labels and predicted result\n",
                "show_preds()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# SOURCE: https://www.kaggle.com/yangdliu/notebook285235a998\n",
                "def to_numpy(tensor: Union[Tensor, Image.Image, np.array]) -> np.ndarray:\n",
                "    \"\"\"\n",
                "    This function is used to convert the format of the image to the desired format\n",
                "    \"\"\"\n",
                "    if type(tensor) == np.array or type(tensor) == np.ndarray:\n",
                "        return np.array(tensor)\n",
                "    elif type(tensor) == Image.Image:\n",
                "        return np.array(tensor)\n",
                "    elif type(tensor) == Tensor:\n",
                "        return tensor.cpu().detach().numpy()\n",
                "    else:\n",
                "        raise ValueError()\n",
                "\n",
                "# Import packages to plot confusion matrix and AUC Score\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn.metrics import roc_auc_score\n",
                "\n",
                "def test_label_predictions(model, device, test_loader):\n",
                "    \"\"\"\n",
                "    This function is used to calculate the confusion matrix and plot the AUC score of the given model\n",
                "    :params model: the loaded trained resnet50 model\n",
                "    :params device: the current location of the model, whether its sent to CPU or GPU\n",
                "    :test_loader: the testloader of the transformed batch of testing dataset\n",
                "    :return: the confusion matrix of model and AUC score \n",
                "    \"\"\"\n",
                "    model.eval()\n",
                "    actuals = []\n",
                "    predictions = []\n",
                "    with torch.no_grad():\n",
                "        for inputs, labels in test_loader:\n",
                "            inputs, labels = inputs.to(device), labels.to(device)\n",
                "            outputs = model(inputs)\n",
                "            prediction = outputs.argmax(dim=1, keepdim=True)\n",
                "            actuals.extend(to_numpy(labels.view_as(prediction)))\n",
                "            predictions.extend(to_numpy(prediction))\n",
                "            \n",
                "    return [i.item() for i in actuals], [i.item() for i in predictions]\n",
                "\n",
                "actuals, predictions = test_label_predictions(model, device, testloader)\n",
                "print('Confusion matrix for resnet50: ')\n",
                "print(confusion_matrix(actuals, predictions))\n",
                "print('AUC score for model resnet50: '+str(roc_auc_score(actuals,predictions)))"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "39a190c749d32fb61bac8622a44c3427ad612ce63b074d3a9247eb6341a0f9c0"
        },
        "kernelspec": {
            "display_name": "Python 3.8.8 64-bit ('base': conda)",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.8"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
